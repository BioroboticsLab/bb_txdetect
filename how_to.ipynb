{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading ground truth data from csv file\n",
    "\n",
    "`load_ground_truth_events` returns a list of `load_data.Event` wich contains metadata about a series of frames that may or may not show trophallaxis.\n",
    "each `Event` has a property `observations`, which is a list of `load_data.Observation` which contains metadata about one frame.\n",
    "The csv format is the one used by Andreas Berg, see help output for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_ground_truth_events in module load_data:\n",
      "\n",
      "load_ground_truth_events(csv_path:str, padding:int) -> [<class 'load_data.Event'>]\n",
      "    Return a list of Event objects, one Event per row in the csv file.\n",
      "    Args:\n",
      "        csv_path: path to the ground truth data. required columns are: \n",
      "            track_id_combination, bee_a_detection_ids,bee_b_detection_ids, \n",
      "            human_decidable_interaction, trophallaxis_observed, \n",
      "            trophallaxis_start_frame_nr, trophallaxis_end_frame_nr\n",
      "        padding: set to a positive value to add extra frames at the beginning and end of each event.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_ground_truth_events\n",
    "help(load_ground_truth_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving the images\n",
    "this will save the images for each event including padding frames before the first and after the last frame. images will be around 600 x 600 to leave room for augmentation.\n",
    "this may take a very long time. for 2007 events it may take many days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function save_images in module get_images:\n",
      "\n",
      "save_images(observations:[<class 'load_data.Observation'>], index:int, image_folder='images_v2_y_events')\n",
      "    Save an image for each Observation. The index is used for naming the folders.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from get_images import save_images\n",
    "help(save_images)\n",
    "\n",
    "events = [] # use return value of load_ground_truth_events\n",
    "for i, event in enumerate(events):\n",
    "    save_images(observations=event.observations, index=i, image_folder=\"raw_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data from individual frames that are not grouped in Events\n",
    "\n",
    "`load_candidates` calls `save_images` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_candidates in module validation:\n",
      "\n",
      "load_candidates(frame_padding_length:int=20, json_file_path:str='/mnt/storage/david/cache/beesbook/trophallaxis/candidate_events.json', output_folder:str='candidates')\n",
      "    load images based on json file. the images will need further preprocessing before use.\n",
      "    json file format:\n",
      "        [[frame_id, bee_id0, bee_id1, x1, y1, x2, y2, cam_id]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from validation import load_candidates\n",
    "help(load_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "after this step, the images are ready for training. this step also takes a long time, but not more than a few hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function preprocess_images in module preprocess_images:\n",
      "\n",
      "preprocess_images(image_folder:str, padding:int=16)\n",
      "    crop and rotate all images and save the processed images \n",
      "    in two folders with the name {image_folder}_pad{padding}[_invert]\n",
      "    Args:\n",
      "        image_folder: input image path\n",
      "        padding: padding that is left around the image on each side.\n",
      "                 so e.g. 128x128 with padding 16 leads to 160x160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocess_images import preprocess_images\n",
    "help(preprocess_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module train:\n",
      "\n",
      "train(seed, rca, item_depth, drop_frames_around_trophallaxis:bool, auto_archive=True, clahe=False, random_rotation_max=0, model_parameters=None, num_epochs=50, log_path='trainlog.txt', stats_path='train_stats.csv', batch_size=64, network=None, save_last_model=False)\n",
      "    train a network, save stats, maybe save the model.\n",
      "    Args:\n",
      "        seed: determines which events go to test and which to train, for cross validaiton.\n",
      "        rca: random crop amplitude, amount of random crops, set to 0 to disable.\n",
      "        item_depth: how many images should the network see for each frame. \n",
      "                    if set to 3 the net sees the center frame and one frame before and after.\n",
      "                    if item_depth is high, training takes longer.\n",
      "        drop_frames_around_trophallaxis: if true ignore all negative frames of all positive events.\n",
      "        auto_archive: if true the stats files get moved automatically to an archive folder\n",
      "        clahe: apply clahe on images\n",
      "        random_rotation_max: maximum angle of random rotations\n",
      "        model_parameters: for models that need additional parameters\n",
      "        network: class of network that should be used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "help(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_validate in module train:\n",
      "\n",
      "cross_validate(num_runs=10, **kwargs)\n",
      "    run train num_runs times with different seeds for cross validation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from train import cross_validate\n",
    "help(cross_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
